{
  "run_name": "20250811_092739_bidirectional_lstm",
  "epochs": 100,
  "lr": 0.001,
  "batch_size": 16,
  "seed": 42,
  "patience": 15,
  "device": "cuda",
  "min_weight": 0.005,
  "components": 40,
  "volatility": 0.14,
  "utility": 5.0,
  "lc_utility": 10.0,
  "lc_components": 5.0,
  "lc_volatility": 0.0,
  "lc_min_weight": 0.0,
  "lookback": 30,
  "holding_period": 5,
  "scheduler_type": "plateau",
  "scaler": true,
  "input_size": 45,
  "stem_dims": [
    64,
    128,
    16
  ],
  "stem_dropout": 0.2,
  "lstm_hidden_dim": 128,
  "lstm_layers": 2,
  "lstm_dropout": 0.1,
  "head_dims": [
    64,
    1
  ],
  "head_dropout": 0.1,
  "activation_name": "gelu",
  "model": "bidirectional_lstm"
}